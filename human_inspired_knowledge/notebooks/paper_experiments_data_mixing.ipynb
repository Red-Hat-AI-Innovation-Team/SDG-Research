{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab/.conda/envs/upstream_sdg/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.chunking import HybridChunker\n",
    "from transformers import AutoTokenizer\n",
    "from instructlab.sdg.utils.parse_and_convert import (\n",
    "    create_auxiliary_dataset,\n",
    "    generate_knowledge_qa_dataset,\n",
    "    build_raft_dataset\n",
    ")\n",
    "import re\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/new_data/knowledge_rh/quality/base_datasets\"\n",
    "def add_icl_examples(ds, qna, seed_example_file_name = \"quality_seed_example.jsonl\"):\n",
    "    global BASE_DIR\n",
    "    new_ds = []\n",
    "    for idx, qa in enumerate(qna):\n",
    "        for e in ds:\n",
    "            new_ds.append(e.copy())\n",
    "            new_ds[-1].update({\n",
    "                f'icl_document': qa['context'],\n",
    "                f'icl_query_1': qa['question_and_answers'][0]['question'], f'icl_response_1': qa['question_and_answers'][0]['answer'],\n",
    "            f'icl_query_2': qa['question_and_answers'][1]['question'], f'icl_response_2': qa['question_and_answers'][1]['answer'],\n",
    "            f'icl_query_3': qa['question_and_answers'][2]['question'], f'icl_response_3': qa['question_and_answers'][2]['answer'],\n",
    "            })\n",
    "    new_ds = Dataset.from_list(new_ds)\n",
    "    print(new_ds)\n",
    "    new_ds.to_json(f\"{BASE_DIR}/{seed_example_file_name}\", orient='records')\n",
    "\n",
    "\n",
    "def _conv_pretrain(rec, tokenizer):\n",
    "    if tokenizer is not None:\n",
    "        rec['unmask'] = True\n",
    "        return rec\n",
    "    rec[\"messages\"] = [\n",
    "        {\n",
    "            \"role\": \"pretraining\",\n",
    "            \"content\": f\"<|user|>\\n{rec['messages'][0]['content']}\\n<|assistant|>\\n{rec['messages'][1]['content']}\",\n",
    "        }\n",
    "    ]\n",
    "    return rec\n",
    "\n",
    "\n",
    "def chunk_document(document):\n",
    "    \"\"\"\n",
    "    Chunk the document into chunks of ~500 tokens\n",
    "    \"\"\"\n",
    "    DOC_SOURCE = \"test.md\"\n",
    "    with open(DOC_SOURCE, 'w') as f:\n",
    "        f.write(document)\n",
    "    doc = DocumentConverter().convert(source=DOC_SOURCE).document\n",
    "    MAX_TOKENS = 500\n",
    "    chunker = HybridChunker(max_tokens=MAX_TOKENS, tokenizer=AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"), merge_peers=True)\n",
    "    chunk_iter = chunker.chunk(dl_doc=doc)\n",
    "    document_chunks = []\n",
    "    for i, chunk in enumerate(chunk_iter):\n",
    "        enriched_text = chunker.serialize(chunk=chunk)\n",
    "        document_chunks.append(enriched_text)\n",
    "    return document_chunks\n",
    "\n",
    "def is_string_complete(s):\n",
    "    # Check if the string ends with common sentence-ending punctuation\n",
    "    if s.endswith((\".\", \"!\", \"?\", '\"', \"'\", \"|\")):\n",
    "        return True\n",
    "\n",
    "    # Check if the string ends with an incomplete word\n",
    "    if re.search(r\"\\b\\w+$\", s) and not re.search(r\"\\b\\w+\\b$\", s):\n",
    "        return False\n",
    "\n",
    "    return False\n",
    "\n",
    "def filter_ds(ds):\n",
    "    ds = ds.map(\n",
    "        lambda x: {\n",
    "            \"question\": x[\"question\"].replace(\"[END]\", \"\").strip(),\n",
    "            \"response\": x[\"response\"].replace(\"[END]\", \"\").strip(),\n",
    "        },\n",
    "        num_proc=72,\n",
    "    )\n",
    "    ds = ds.filter(lambda x: is_string_complete(x[\"question\"]), num_proc=72)\n",
    "    ds = ds.filter(lambda x: is_string_complete(x[\"response\"]), num_proc=72)\n",
    "    ds = ds.filter(lambda x: '[QUESTION]' not in x['question'] and '[ANSWER]' not in x['response'])\n",
    "    return ds\n",
    "\n",
    "def create_training_mix(ds, create_summary=False, model_name=None, keep_context_separate=False, add_raft=False):\n",
    "    if model_name is not None:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    knowl_train = generate_knowledge_qa_dataset(ds, keep_context_separate=keep_context_separate)\n",
    "    knowl_train_pretrain = knowl_train.map(_conv_pretrain, fn_kwargs={\"tokenizer\": tokenizer}, num_proc=10)\n",
    "    if add_raft:\n",
    "        knowl_train_c = generate_knowledge_qa_dataset(ds, keep_context_separate=True)\n",
    "        knowledge_ds_raft = build_raft_dataset(knowl_train_c, p=0.4)\n",
    "        knowledge_ds_raft = knowledge_ds_raft.add_column(\"unmask\", [False] * len(knowledge_ds_raft))\n",
    "    print(f\"Using model {model_name} as chat template\")\n",
    "    if create_summary:\n",
    "        summary_ds = create_auxiliary_dataset(ds)\n",
    "        summary_ds_07 = summary_ds.map(_conv_pretrain, fn_kwargs={\"tokenizer\": tokenizer})\n",
    "        if add_raft:\n",
    "            phase07_train = concatenate_datasets([knowl_train_pretrain, summary_ds_07, knowledge_ds_raft])\n",
    "        else:\n",
    "            phase07_train = concatenate_datasets([knowl_train_pretrain, summary_ds_07])\n",
    "    else:\n",
    "        phase07_train = knowl_train_pretrain\n",
    "        if add_raft:\n",
    "            phase07_train = concatenate_datasets([phase07_train, knowledge_ds_raft])\n",
    "    return phase07_train\n",
    "\n",
    "def sample_per_doc(ds, final_dataset_size):\n",
    "    random.seed(42)\n",
    "    df = ds.to_pandas()\n",
    "    per_doc_size = final_dataset_size // len(df['document'].unique()) + 1\n",
    "    # First combine question and response pairs\n",
    "    df['qa_pair'] = list(zip(df['question'], df['response']))\n",
    "\n",
    "    grouped_df = df.groupby('document').agg({\n",
    "        'qa_pair': lambda x: random.sample(list(x), min(per_doc_size, len(x))),\n",
    "        'domain': lambda x: random.sample(list(x), min(per_doc_size, len(x))),\n",
    "        'document_outline': lambda x: random.sample(list(x), min(per_doc_size, len(x))),\n",
    "    }).reset_index()\n",
    "\n",
    "    # Split the qa_pairs back into separate columns\n",
    "    grouped_df['question'] = grouped_df['qa_pair'].apply(lambda x: [pair[0] for pair in x])\n",
    "    grouped_df['response'] = grouped_df['qa_pair'].apply(lambda x: [pair[1] for pair in x])\n",
    "    grouped_df = grouped_df.drop('qa_pair', axis=1)\n",
    "\n",
    "    # Convert back to grouped_df format\n",
    "    df_subset = grouped_df.explode(['question', 'response']).reset_index(drop=True)\n",
    "    return Dataset.from_pandas(df_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entigraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model meta-llama/Meta-Llama-3-8B-Instruct as chat template\n",
      "Dataset({\n",
      "    features: ['messages', 'unmask'],\n",
      "    num_rows: 40704\n",
      "})\n",
      "Dataset({\n",
      "    features: ['messages', 'unmask'],\n",
      "    num_rows: 81409\n",
      "})\n",
      "Dataset({\n",
      "    features: ['messages', 'unmask'],\n",
      "    num_rows: 162818\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 41/41 [00:01<00:00, 29.58ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 82/82 [00:02<00:00, 36.53ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 163/163 [00:04<00:00, 36.55ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 82/82 [00:02<00:00, 28.52ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 163/163 [00:06<00:00, 24.06ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 326/326 [00:11<00:00, 28.93ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1647092578"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds_1 = load_dataset('json', data_dir=\"/new_data/knowledge_rh/quality/entigraph_knowledge1.0_phi4_first_24_n_5/gen/\", split=\"train\")\n",
    "ds_1 = ds_1.filter(lambda x: x['score'] == '2' and x['judgment'] == 'YES')\n",
    "ds_1 = filter_ds(ds_1)\n",
    "ds_1 = ds_1.add_column('domain', [\"articles\"]*ds_1.num_rows)\n",
    "ds_1 = ds_1.add_column('raw_document', ds_1['document'])\n",
    "ds_1 = create_training_mix(ds_1, create_summary=False, model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "ds_1  = ds_1.remove_columns(['metadata', 'id'])\n",
    "ds_1 = ds_1.shuffle(seed=42)\n",
    "ds_1_25_percent = ds_1.select(range(int(len(ds_1) * 0.25)))\n",
    "ds_1_50_percent = ds_1.select(range(int(len(ds_1) * 0.5)))\n",
    "ds_1_100_percent = ds_1\n",
    "print(ds_1_25_percent)\n",
    "print(ds_1_50_percent)\n",
    "print(ds_1_100_percent)\n",
    "ds_1_25_percent.to_json(f\"/new_data/knowledge_rh/quality/training_mix/entigraph_knowledge1.0_phi4_first_24_n_5_25_percent.jsonl\", orient='records', lines=True)\n",
    "ds_1_50_percent.to_json(f\"/new_data/knowledge_rh/quality/training_mix/entigraph_knowledge1.0_phi4_first_24_n_5_50_percent.jsonl\", orient='records', lines=True)\n",
    "ds_1_100_percent.to_json(f\"/new_data/knowledge_rh/quality/training_mix/entigraph_knowledge1.0_phi4_first_24_n_5_100_percent.jsonl\", orient='records', lines=True)\n",
    "\n",
    "\n",
    "\n",
    "ultra_chat_ds = load_dataset(\n",
    "        \"HuggingFaceH4/ultrachat_200k\",\n",
    "        trust_remote_code=True,\n",
    "        split=\"train_sft\"\n",
    "    )\n",
    "ultra_chat_ds = ultra_chat_ds.remove_columns(['prompt', 'prompt_id']).add_column('unmask', [False]*ultra_chat_ds.num_rows)\n",
    "ultra_chat_ds_25_percent = ultra_chat_ds.shuffle(seed=42).select(range(len(ds_1_25_percent)))\n",
    "ultra_chat_ds_50_percent = ultra_chat_ds.shuffle(seed=42).select(range(len(ds_1_50_percent)))\n",
    "ultra_chat_ds_100_percent = ultra_chat_ds.shuffle(seed=42).select(range(len(ds_1_100_percent)))\n",
    "\n",
    "ds = concatenate_datasets([ds_1_25_percent, ultra_chat_ds_25_percent])\n",
    "ds.to_json(f\"/new_data/knowledge_rh/quality/training_mix/entigraph_knowledge1.0_phi4_first_24_n_5_25_percent_ultra_chat.jsonl\", orient='records', lines=True)\n",
    "\n",
    "ds = concatenate_datasets([ds_1_50_percent, ultra_chat_ds_50_percent])\n",
    "ds.to_json(f\"/new_data/knowledge_rh/quality/training_mix/entigraph_knowledge1.0_phi4_first_24_n_5_50_percent_ultra_chat.jsonl\", orient='records', lines=True)\n",
    "\n",
    "ds = concatenate_datasets([ds_1_100_percent, ultra_chat_ds_100_percent])\n",
    "ds.to_json(f\"/new_data/knowledge_rh/quality/training_mix/entigraph_knowledge1.0_phi4_first_24_n_5_100_percent_ultra_chat.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "upstream_sdg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
